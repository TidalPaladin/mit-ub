fit:
  compile: true
  float32_matmul_precision: medium
  trainer:
    accelerator: gpu
    devices: [1]
    #strategy: "ddp_find_unused_parameters_true"
    precision: "bf16-mixed"
    max_steps: 50000
    num_sanity_val_steps: 0
    default_root_dir: /mnt/storage/users/chase/mitub
    check_val_every_n_epoch: 10

    callbacks:
      - class_path: pytorch_lightning.callbacks.ModelCheckpoint
        init_args:
          filename: "epoch={epoch}-step={step}-loss={val/loss:.4f}"
          monitor: "val/loss"
          auto_insert_metric_name: false
          mode: min
          save_last: true

      - class_path: pytorch_lightning.callbacks.LearningRateMonitor
        init_args:
          log_momentum: true

      - class_path: mit_ub.callbacks.HistogramCallback
        init_args:
          name: histogram

    logger:
      class_path: pytorch_lightning.loggers.wandb.WandbLogger
      init_args:
        save_dir: /mnt/storage/users/chase/mitub
        project: mit-ub
        name: "bf16"

  model:
    class_path: mit_ub.tasks.JEPAWithClassification
    init_args:
      backbone: "vit-cifar10"
      num_classes: 10

      loss_fn: "cosine"
      margin: 0.5

      context_scale: 2
      optimizer_init:
        class_path: torch.optim.AdamW
        init_args:
          lr: 0.0005
          weight_decay: 0.05
      lr_interval: "step"
      lr_scheduler_init:
        class_path: torch.optim.lr_scheduler.OneCycleLR
        init_args:
          max_lr: 0.0005
          div_factor: 5
          final_div_factor: 50
          pct_start: 0.10
          three_phase: false
          total_steps: 50000

  data:
    class_path: mit_ub.data.CIFAR10DataModule
    init_args:
      root: /mnt/active_1/chase/cifar10/cifar-10-batches-py
      batch_size: 512
      num_workers: 24
      pin_memory: true

      train_transforms:
        class_path: torchvision.transforms.v2.Compose
        init_args:
          transforms:
            - class_path: torchvision.transforms.v2.RandomHorizontalFlip
              init_args:
                p: 0.5

            - class_path: torchvision.transforms.v2.RandomVerticalFlip
              init_args:
                p: 0.5

            - class_path: torchvision.transforms.v2.ToTensor

            - class_path: mit_ub.data.dynamic_range.CompressDynamicRange
              init_args:
                # Slightly more than 4 / 2 ** 14
                max_val: 0.00025

      val_transforms:
        class_path: torchvision.transforms.v2.Compose
        init_args:
          transforms:
            - class_path: torchvision.transforms.v2.ToTensor

            - class_path: mit_ub.data.dynamic_range.CompressDynamicRange
              init_args:
                # Slightly more than 4 / 2 ** 14
                max_val: 0.00025
