fit:
  compile: true
  float32_matmul_precision: medium
  trainer:
    accelerator: gpu
    devices: 2
    strategy: "ddp"
    precision: "bf16-mixed"
    max_steps: 150000
    num_sanity_val_steps: 0
    default_root_dir: /mnt/storage/users/chase/mitub
    #val_check_interval: 5000
    callbacks:
      - class_path: pytorch_lightning.callbacks.ModelCheckpoint
        init_args:
          filename: "epoch={epoch}-step={step}-loss={val/loss:.4f}"
          monitor: "val/loss"
          auto_insert_metric_name: false
          mode: min
          save_last: true

      - class_path: pytorch_lightning.callbacks.LearningRateMonitor
        init_args:
          log_momentum: true

      - class_path: mit_ub.callbacks.HistogramCallback
        init_args:
          name: histogram

    logger:
      class_path: pytorch_lightning.loggers.wandb.WandbLogger
      init_args:
        save_dir: /mnt/storage/users/chase/mitub
        project: mit-ub
        name: mitub-rev4-large-mjepa-p2

  model:
    class_path: mit_ub.tasks.JEPAWithViewPosition
    init_args:
      # NOTE: Between p1 and p2 we remove token noise and add LayerNorm to the backbone output
      backbone: "vit-i1-p16-d768-a32_24"
      checkpoint: "/mnt/storage/users/chase/mitub/mit-ub/6jrzunrx/checkpoints/last.ckpt"
      #checkpoint: "/mnt/storage/users/chase/mitub/mit-ub/mqvbxr6s/checkpoints/last.ckpt"
      #checkpoint: /mnt/storage/users/chase/mitub/mit-ub/f8h7jbed/checkpoints/last.ckpt
      #checkpoint: /mnt/storage/users/chase/mitub/mit-ub/yhypecnp/checkpoints/last.ckpt
      strict_checkpoint: false

      # JEPA config
      context_ratio: 0.5
      context_scale: 4
      target_ratio: 0.25
      target_scale: 2
      predictor_depth: 6
      dist_gather: true

      log_train_metrics_interval: 50
      optimizer_init:
        class_path: torch.optim.AdamW
        init_args:
          lr: 0.000025
          weight_decay: 0.05
      lr_interval: "step"
      lr_scheduler_init:
        class_path: torch.optim.lr_scheduler.OneCycleLR
        init_args:
          max_lr: 0.000025
          div_factor: 1
          final_div_factor: 50
          pct_start: 0.01
          three_phase: false
          total_steps: 150000

  data:
    class_path: torch_dicom.preprocessing.datamodule.PreprocessedPNGDataModule
    init_args:

      train_inputs: 
        - "/mnt/active_1/chase/data/optimam_highres"
        - "/mnt/active_1/chase/data/medcog_highres"
        #- /mnt/active_1/chase/data/test
      val_inputs: /mnt/active_1/chase/data/test

      metadata_filenames:
        manifest: "manifest.csv"

      # For some reason we get deadlocks at the end of epoch 3 at batch size 16
      batch_size: 12
      num_workers: 12

      train_transforms:
        class_path: torchvision.transforms.v2.Compose
        init_args:
          transforms:
            - class_path: torchvision.transforms.v2.RandomResizedCrop
              init_args:
                size: [2048, 1536]
                scale: [0.8, 1.0]
                ratio: [0.8, 1.2]
                antialias: true

      train_gpu_transforms:
        class_path: torchvision.transforms.v2.Compose
        init_args:
          transforms:
            - class_path: torchvision.transforms.v2.RandomHorizontalFlip
              init_args:
                p: 0.5

            - class_path: torchvision.transforms.v2.RandomVerticalFlip
              init_args:
                p: 0.5

            - class_path: torchvision.transforms.v2.ColorJitter
              init_args:
                brightness: 0.2
                contrast: 0.2

            - class_path: torchvision.transforms.v2.RandomInvert
              init_args:
                p: 0.5